{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione lineare multipla\n",
    "La regressione lineare multipla o multivariata è un caso di regressione lineare con due o più variabili indipendenti.\n",
    "\n",
    "Se ci sono solo due variabili indipendenti, la funzione di regressione stimata è 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂. Rappresenta un piano di regressione in uno spazio tridimensionale. L'obiettivo della regressione è determinare i valori dei pesi 𝑏₀, 𝑏₁ e 𝑏₂ in modo tale che questo piano sia il più vicino possibile alle risposte effettive, producendo al contempo l'SSR minimo.\n",
    "\n",
    "Il caso di più di due variabili indipendenti è simile, ma più generale. La funzione di regressione stimata è 𝑓(𝑥₁, …, 𝑥ᵣ) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ +𝑏ᵣ𝑥ᵣ, e ci sono 𝑟 + 1 pesi da determinare quando il numero di input è 𝑟."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementiamo la Regressione lineare multipla con scikit-learn\n",
    "È possibile implementare una regressione lineare multipla seguendo gli stessi passaggi della regressione semplice. La differenza principale è che ora il nostro x array avrà due o più colonne.\n",
    "\n",
    "#### Passaggi 1 e 2: importiamo pacchetti e classi e forniamo i dati\n",
    "\n",
    "Innanzitutto, importiamo numpy e sklearn.linear_model.LinearRegression e forniamo input e output noti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = [\n",
    "  [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n",
    "]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 5,  1],\n",
       "       [15,  2],\n",
       "       [25,  5],\n",
       "       [35, 11],\n",
       "       [45, 15],\n",
       "       [55, 34],\n",
       "       [60, 35]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 20, 14, 32, 22, 38, 43])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come abbiamo già detto, nella regressione lineare multipla, x è una matrice bidimensionale con almeno due colonne, mentre y di solito è una matrice unidimensionale. Questo è un semplice esempio di regressione lineare multipla e x ha esattamente due colonne.\n",
    "\n",
    "### Passaggio 3: creiamo un modello e lo adattiamo\n",
    "\n",
    "Il passaggio successivo consiste nel creare il modello di regressione come istanza LinearRegressione per poi allenarlo con .fit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato di questa istruzione è la variabile model che fa riferimento all'oggetto di tipo LinearRegression. Rappresenta il modello di regressione adattato ai dati esistenti.\n",
    "\n",
    "### Passaggio 4: ottieniamo i risultati\n",
    "\n",
    "È possibile ottenere le proprietà del modello come nel caso della regressione lineare semplice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8615939258756776\n",
      "intercept: 5.52257927519819\n",
      "coefficients: [0.44706965 0.25502548]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ottiene il valore di 𝑅² utilizzando .score() i valori degli stimatori dei coefficienti di regressione con .intercept_e .coef_. Ancora una volta, .intercept_ mantiene il bias 𝑏₀, mentre ora .coef_è un array contenente 𝑏₁ e 𝑏₂.\n",
    "\n",
    "In questo esempio, l'intercetta è circa 5,52 e questo è il valore della risposta prevista quando 𝑥₁ = 𝑥₂ = 0. Un aumento di 𝑥₁ di 1 produce un aumento della risposta prevista di 0,45. Allo stesso modo, quando 𝑥₂ cresce di 1, la risposta aumenta di 0,26.\n",
    "\n",
    "### Passaggio 5: prevedere la risposta\n",
    "\n",
    "Anche le previsioni funzionano allo stesso modo del caso della regressione lineare semplice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La risposta prevista si ottiene con .predict(), che equivale alla seguente formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis=1)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possibile prevedere i valori di output moltiplicando ciascuna colonna dell'input con il peso appropriato, per poi sommare questo valore con l'intercetta.\n",
    "\n",
    "Possiamo applicare questo modello anche a nuovi dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.77760476,  7.18179502,  8.58598528,  9.99017554, 11.3943658 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = np.arange(10).reshape((-1, 2))\n",
    "x_new\n",
    "\n",
    "y_new = model.predict(x_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primo Esempio pratico\n",
    "### Analizzando il dataset cardata.csv possiamo prevedere le emissioni CO2 in base alle dimensioni del motore e al peso dell'auto, con la possibilità di analizzare 2 carretteristiche invece che una sola possiamo infatti rendere la previsione più accurata.\n",
    "\n",
    "\n",
    "Prima cosa da fare importiamo scikit-learn per il modello e pandas per leggere il csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import linear_model\n",
    "df = pandas.read_csv(\"cardata.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizzato il dataset possiamo creare le nostre variabili:\n",
    "- X per contenente i valori indipendenti;\n",
    "- y per contenere i valori target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poi utilizziamo il nostro modello e il metodo .fit() per allenarerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = regr.score(X, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_pred)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo prevedere i valori di CO2 in base al peso e al volume di un'auto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the CO2 emission of a car where the weight is 2300kg, and the volume is 1300cm3:\n",
    "predictedCO2 = regr.predict([[2300, 1300]])\n",
    "print(predictedCO2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passiamo al Coefficiente\n",
    "Abbiamo detto che il coefficiente è un fattore che descrive la relazione con una variabile sconosciuta.\n",
    "\n",
    "In questo caso, possiamo chiedere il valore del coefficiente di peso rispetto a CO2 e di volume rispetto a CO2. Le risposte che otteniamo ci dicono cosa accadrebbe se aumentassimo o diminuissimo uno dei valori indipendenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice dei risultati rappresenta i valori dei coefficienti di peso e volume.\n",
    "\n",
    "Peso: 0,00755095\n",
    "Volume: 0,00780526\n",
    "\n",
    "Questi valori ci dicono che se il peso aumenta di 1kg, l'emissione di CO2 aumenta di 0,00755095g.\n",
    "\n",
    "E se la cilindrata (Volume) aumenta di 1 centimentro cubo, l'emissione di CO2 aumenta di 0,00780526 g.\n",
    "\n",
    "Considerando che sia una supposizione giusta andiamo a fare altre prove.\n",
    "\n",
    "Abbiamo già previsto che se un'auto con motore da 1300 cm 3 pesa 2300 kg, l'emissione di CO2 sarà di circa 107 g.\n",
    "\n",
    "Cosa succede se aumentiamo il peso di 1000 kg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedCO2 = regr.predict([[3300, 1300]])\n",
    "\n",
    "print(predictedCO2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo previsto che un'auto con motore da 1,3 litri e peso di 3300 kg rilascerà circa 115 grammi di CO2 per ogni chilometro percorso.\n",
    "\n",
    "Ciò dimostra che il coefficiente di 0,00755095 è corretto:\n",
    "\n",
    "107,2087328 + (1000 * 0,00755095) = 114,75968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "X_stand = X_scaler.fit_transform(X)\n",
    "\n",
    "X_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primo Esercizio\n",
    " Utilizzate la linear regression multipla per analizzare il dataframe a questo link https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression utilizzate i dati sulle ore di studio e le ore di sonno , allenate l'algoritmo, testatelo e poi realizzate i vari grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secono Esercizio\n",
    "Utilizzate la linear regression multipla per analizzare il dataframe a questo link https://www.kaggle.com/datasets/quantbruce/real-estate-price-prediction utilizzate i dati sulle età delle case e la distanza dalla metro per prevedere il costo della casa , allenate l'algoritmo, testatelo e poi realizzate i vari grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz = {\"chiave\":\"valore\",\"chiave2\":\"valore2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.pkl\", \"wb\") as f:\n",
    "    pickle.dump(diz, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.pkl\", \"rb\") as f:\n",
    "    diz2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL = \"trained_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINED_MODEL, \"wb\") as f:\n",
    "    pickle.dump(regr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINED_MODEL, \"rb\") as f:\n",
    "    trained_regressor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione polinomiale\n",
    "Se i nostri punti chiaramente non si adattano a una regressione lineare (una linea retta che passa attraverso tutti i punti dati), potrebbe essere ideale utilizzare la regressione polinomiale.\n",
    "\n",
    "La regressione polinomiale, come la regressione lineare, utilizza la relazione tra le variabili X e y per trovare il modo migliore per tracciare una linea attraverso i punti dati.\n",
    "\n",
    "\n",
    "\n",
    "![grafico](./dati/img/img_polynomial_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione polinomiale con scikit-learn\n",
    "L'implementazione della regressione polinomiale con scikit-learn è molto simile alla regressione lineare. Ma c'è solo un passaggio in più: dobbiamo trasformare l'array di input per includere termini non lineari come 𝑥².\n",
    "\n",
    "### Passaggio 1: importiamo pacchetti e classi\n",
    "\n",
    "Oltre a numpy e sklearn.linear_model.LinearRegression, dobbiamo anche importare la classe PolynomialFeatures da sklearn.preprocessing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'importazione è ora completata e abbiamo tutto ciò di cui abbiamo bisogno per lavorare.\n",
    "\n",
    "### Passaggio 2a: forniamo i dati\n",
    "\n",
    "Questo passaggio definisce l'input e l'output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora abbiamo l'input e l'output in un formato adatto. Dobbiamo ricordarci che è necessario che l'input sia un array bidimensionale . Ecco perché .reshape() viene utilizzato.\n",
    "\n",
    "### Passaggio 2b: trasformarmiamo i dati di input\n",
    "\n",
    "Questo è il nuovo passaggio che dobbiamo implementare per la regressione polinomiale!\n",
    "\n",
    "Come abbiamo imparato in precedenza, dobbiamo includere 𝑥² come funzionalità aggiuntive quando implementiamo la regressione polinomiale. Per questo motivo, dobbiamo trasformare l'array di input X per contenere eventuali colonne aggiuntive con i valori di 𝑥² ed eventualmente più funzionalità.\n",
    "\n",
    "È possibile trasformare l'array di input in diversi modi, ad esempio utilizzando insert() from numpy. Ma nel nostro caso la funzione PolynomialFeatures è molto più conveniente per questo scopo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PolynomialFeatures(degree=2, include_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variabile transformer si riferisce a un'istanza PolynomialFeatures che è possibile utilizzare per trasformare l'input X.\n",
    "\n",
    "È possibile fornire diversi parametri facoltativi per PolynomialFeatures:\n",
    "\n",
    "- degree è un numero intero ( 2 per impostazione predefinita) che rappresenta il grado della funzione di regressione polinomiale.\n",
    "- interaction_only è un valore booleano ( False per impostazione predefinita) che decide se includere solo le funzionalità di interazione ( True) o tutte le funzionalità ( False).\n",
    "- include_bias è un valore booleano ( True per impostazione predefinita) che decide se includere la colonna di valori ( True) o meno ( False).\n",
    "\n",
    "In questo esempio vengono utilizzati i valori predefiniti di tutti i parametri tranne include_bias. A volte vorrai sperimentare il grado della funzione e può essere utile per la leggibilità fornire comunque questo argomento.\n",
    "\n",
    "Prima di applicare transformer è necessario munirlo di .fit(), una volta fatto è pronto per creare un nuovo array di input modificato. Utilizziamo .transform() per farlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.fit(x)\n",
    "x_ = transformer.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa trasformazione dell'array di input con .transform() prende l'array di input come argomento e restituisce l'array modificato.\n",
    "\n",
    "Per velocità si può anche usare .fit_transform() per sostituire le tre affermazioni precedenti con una sola:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con .fit_transform(), stiamo adattando e trasformando l'array di input in un'unica istruzione. Anche questo metodo accetta l'array di input e fa effettivamente la stessa cosa di .fit() e .transform()c hiamato in quest'ordine. Restituisce anche l'array modificato. Ecco come appare il nuovo array di input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'array di input modificato contiene due colonne: una con gli input originali e l'altra con i relativi quadrati.\n",
    "\n",
    "### Passaggio 3: creiamo un modello e adattalo\n",
    "\n",
    "Anche questo passaggio è lo stesso del caso della regressione lineare. Creiamo e adattiamo il ​​modello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello di regressione è ora creato e adattato. È pronto per l'applicazione. Ricordiamoci che il primo argomento di .fit() è l' array di input modificato x_ e non l'originale x.\n",
    "\n",
    "### Passaggio 4: ottieniamo i risultati\n",
    "\n",
    "È possibile ottenere le proprietà del modello allo stesso modo del caso della regressione lineare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ancora una volta, .score() ritorna 𝑅². Anche il suo primo argomento è l'input modificato x_, non x. I valori dei pesi sono associati a .intercept_ e .coef_. Qui .intercept_ rappresenta 𝑏₀, mentre .coef_ fa riferimento all'array che contiene 𝑏₁ e 𝑏₂.\n",
    "\n",
    "### Passaggio 5: prevedere la risposta\n",
    "\n",
    "Se vogliamo ottenere la risposta prevista, usiamo semplicemente .predict(), ma ricordiamo che l'argomento dovrebbe essere l'input modificato x_ anziché il vecchio x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, la previsione funziona quasi allo stesso modo del caso della regressione lineare. Richiede solo l'input modificato anziché l'originale.\n",
    "\n",
    "È possibile applicare una procedura identica se si hanno più variabili di input . Avremo un array di input con più di una colonna, ma tutto il resto sarà lo stesso. Ecco un esempio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2 a: Provide data\n",
    "x = [\n",
    "  [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n",
    "]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2 b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Step 5: Predict response\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo esempio di regressione produce i seguenti risultati e previsioni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "\n",
    "\n",
    "print(f\"intercept: {intercept}\")\n",
    "\n",
    "\n",
    "print(f\"coefficients:\\n{coefficients}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo notare che la regressione polinomiale ha prodotto un coefficiente di determinazione più elevato rispetto alla regressione lineare multipla per lo stesso problema. Inizialmente si potrebbe pensare che ottenere un 𝑅² così grande sia un ottimo risultato.\n",
    "\n",
    "Tuttavia, nelle situazioni del mondo reale, anche avere un modello complesso e 𝑅² molto vicino a uno potrebbe essere un problema di overfitting (di cui parleremo a brevissimo). Per verificare le prestazioni di un modello, dovremmo testarlo con nuovi dati, ovvero con osservazioni non utilizzate per adattare o addestrare il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altro esempio\n",
    "\n",
    "Nell'esempio seguente abbiamo immortalato 18 automobili mentre transitavano davanti ad un determinato casello.\n",
    "\n",
    "Abbiamo registrato la velocità dell'auto e l'ora del giorno in cui è avvenuto il passaggio.\n",
    "\n",
    "L'asse x rappresenta le ore del giorno e l'asse y rappresenta la velocità, iniziamo disegnando un grafico a dispersione:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usiamo numpy per creare un modello polinomiale:\n",
    "import numpy\n",
    "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
    "\n",
    "#Quindi specifichiamo come verrà visualizzata la linea, iniziamo dalla posizione 1 e terminiamo alla posizione 22:\n",
    "\n",
    "myline = numpy.linspace(1, 22, 100)\n",
    "\n",
    "#Disegnamo il grafico a dispersione originale:\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "#Disegna la linea di regressione polinomiale:\n",
    "\n",
    "plt.plot(myline, mymodel(myline))\n",
    "\n",
    "#Visualizza il diagramma:\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente è importante sapere quanto è buona la relazione tra i valori degli assi x e y, se non esiste alcuna relazione la regressione polinomiale non può essere utilizzata per prevedere nulla.\n",
    "\n",
    "Misuriamo la relazione con il valore r-quadrato che ricordiamo varia da 0 a 1, dove 0 significa nessuna relazione e 1 significa correlato al 100%.\n",
    "\n",
    "Come abbiamo già visto, Python e il modulo Sklearn calcoleranno questo valore per noi, tutto ciò che dobbiamo fare è alimentarlo con gli array X e y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "\n",
    "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
    "\n",
    "print(r2_score(y, mymodel(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il risultato 0,94 mostra che esiste un'ottima relazione e possiamo utilizzare la regressione polinomiale nelle previsioni future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ora torniamo alle slide per parlare dell'overfitting e underfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
