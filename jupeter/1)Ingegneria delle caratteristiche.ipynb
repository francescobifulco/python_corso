{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQ54W1GEvcy"
      },
      "source": [
        "# Ingegneria delle caratteristiche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OBnKwyOcEvcz"
      },
      "source": [
        "Finora la maggior parte degli esempi presupponevano che i dati numerici erano in un formato ordinato [n_samples, n_features]. Nel mondo reale, i dati raramente arrivano in questa forma. Con questo in mente, uno dei passaggi più importanti nell'utilizzo pratico del machine learning è l'ingegneria delle caratteristiche : ovvero, prendere tutte le informazioni che abbiamo sul nostro problema e trasformarle in numeri che possiamo utilizzare per costruire la matrice delle caratteristiche.\n",
        "\n",
        "Andremo ora a trattare alcuni esempi comuni di attività di ingegneria delle funzionalità: funzionalità per rappresentare dati categoriali , funzionalità per rappresentare testo e funzionalità per rappresentare immagini . Inoltre, discuteremo le funzionalità derivate per aumentare la complessità del modello e l'imputazione dei dati mancanti. Spesso questo processo è noto come vettorizzazione , poiché comporta la conversione di dati arbitrari in vettori ben funzionanti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "aoQ32boiEvc0"
      },
      "source": [
        "## Caratteristiche categoriche\n",
        "\n",
        "Un tipo comune di dati non numerici sono i dati categoriali, a esempio, immaginiamo di esplorare alcuni dati sui prezzi delle case, insieme a caratteristiche numeriche come \"prezzo\" e \"camere\", di avere anche informazioni sul \"quartiere\": "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "qlPvAyPeEvc0",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},\n",
        "    {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},\n",
        "    {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},\n",
        "    {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df =pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "EKHBjbLXEvc1"
      },
      "source": [
        "Potremmo essere tentato di codificare questi dati con una semplice mappatura numerica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iYlbEaR9Evc1",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "{'Queen Anne': 1, 'Fremont': 2, 'Wallingford': 3}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per questo ci può aiutare LabelEncoder: converte stringhe (o etichette categoriali) in\n",
        "valori numerici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "x_encoded = le.fit_transform(df[\"neighborhood\"])\n",
        "x_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iOEl6ALsEvc1"
      },
      "source": [
        "Questo però non è generalmente un approccio utile in Scikit-Learn: i modelli del pacchetto partono dal presupposto fondamentale che le caratteristiche numeriche riflettono quantità algebriche. Pertanto una tale mappatura implicherebbe, ad esempio, che Queen Anne < Fremont < Wallingford , o anche che Wallingford - Queen Anne = Fremont , il che non ha molto senso.\n",
        "\n",
        "In questo caso, una tecnica collaudata consiste nell'utilizzare la codifica one-hot , che crea effettivamente colonne aggiuntive che indicano la presenza o l'assenza di una categoria con un valore rispettivamente di 1 o 0. Quando i nostri dati arrivano come un elenco di dizionari, Scikit-Learn DictVectorizer li trasformerà in vettori per noi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rD4YNqebEvc2",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "cbbdfe25-31ea-4f04-a4ea-f9aa85d66b9e"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse=False, dtype=int)\n",
        "vec.fit_transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WWqHxxlMEvc2"
      },
      "source": [
        "Notiamo che la colonna \"quartiere\" è stata espansa in tre colonne separate, che rappresentano le tre etichette di quartiere, e che ciascuna riga ha un 1 nella colonna associata al suo quartiere. Con queste caratteristiche categoriche così codificate, possiamo procedere normalmente con l'adattamento di un modello Scikit-Learn.\n",
        "\n",
        "Per vedere il significato di ciascuna colonna, possiamo controllare i nomi delle funzionalità:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ZU_RNNeNEvc2",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b18dfb97-8d63-420b-86bf-d9b927f3357d"
      },
      "outputs": [],
      "source": [
        "vec.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zbRPS57jEvc3"
      },
      "source": [
        "C'è un chiaro svantaggio di questo approccio: se la nostra categoria ha molti valori possibili, ciò può aumentare notevolmente la dimensione del set di dati. Tuttavia, poiché i dati codificati contengono principalmente zeri, un output sparso può essere una soluzione molto efficiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wFXsDLfMEvc3",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d7323a8e-ed12-4442-aad2-de7baf5cd090"
      },
      "outputs": [],
      "source": [
        "vec = DictVectorizer(sparse=True, dtype=int)\n",
        "X =vec.fit_transform(data)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con Pandas possiamo poi visualizzare correttamente questa matrice sparsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zYJ7O4F9Evc3"
      },
      "source": [
        "Molti stimatori di Scikit-Learn accettano input così sparsi quando adattano e valutano i modelli. sklearn.preprocessing.OneHotEncoder e sklearn.feature_extraction.FeatureHasher sono due strumenti aggiuntivi che Scikit-Learn inclusi per supportare questo tipo di codifica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=[[\"casa\",\"no\"],[\"non casa\",\"si\"],[\"casa\",\"no\"],[\"non casa\",\"si\"]]\n",
        "y =[0,1,0,1]\n",
        "\n",
        "X = pd.DataFrame(x)\n",
        "y =pd.Series(y)\n",
        "X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing: encoder per colonna categorica\n",
        "one_hot= OneHotEncoder(sparse_output=False)\n",
        "\n",
        "X=one_hot.fit_transform(X)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(C=1e5)\n",
        "logreg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred =logreg.predict(X)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "var =classification_report(y,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zeNad95HEvc3"
      },
      "source": [
        "## Caratteristiche del testo\n",
        "\n",
        "Un'altra esigenza comune nell'ingegneria delle funzionalità è convertire il testo in un insieme di valori numerici rappresentativi. A esempio, la maggior parte dell’estrazione automatica dei dati dei social media si basa su una qualche forma di codifica del testo come numeri, uno dei metodi più semplici per codificare i dati è il conteggio delle parole : prendiamo ogni frammento di testo, contiamo le occorrenze di ogni parola al suo interno e inseriamo i risultati in una tabella.\n",
        "\n",
        "Partiamo da queste tre frasi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bKbdJ8sREvc3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = ['problem of evil',\n",
        "          'evil queen',\n",
        "          'horizon problem']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TUi3zYsOEvc3"
      },
      "source": [
        "Per una vettorizzazione di questi dati basata sul conteggio delle parole, potremmo costruire una colonna che rappresenti la parola \"problem\", la parola \"evil\", la parola \"horizon\" e così via. Sebbene farlo manualmente sia possibile, la noia può essere evitata utilizzando Scikit-Learn CountVectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "q6P9lblHEvc3",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8cbf4e18-69b5-4a97-e88a-81a91aadc386"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(sample)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OHFV9aasEvc3"
      },
      "source": [
        "Il risultato è una matrice sparsa che registra il numero di volte in cui appare ciascuna parola; è più facile da controllare se lo convertiamo in un file DataFramecon colonne etichettate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bayMqLvpEvc3",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "9f5e1969-fc6c-4680-a5ac-b367f59e298d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Egnc0R3SEvc3"
      },
      "source": [
        "Ci sono tuttavia alcuni problemi con questo approccio: i conteggi grezzi delle parole portano a caratteristiche che danno troppo peso alle parole che appaiono molto frequentemente, e questo può non essere ottimale in alcuni algoritmi di classificazione. Un approccio per risolvere questo problema è noto come frequenza del documento inversa alla frequenza ( TF-IDF ) che pondera il conteggio delle parole in base alla frequenza con cui appaiono nei documenti. La sintassi per calcolare queste funzionalità è simile all'esempio precedente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "83wyTMMSEvc4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1ff047cb-95ae-4835-c745-a60a5d4f69c5"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer()\n",
        "X = vec.fit_transform(sample)\n",
        "pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dinBAPOTEvc4"
      },
      "source": [
        "## Funzionalità derivate\n",
        "\n",
        "Un altro tipo di funzionalità utile è quella derivata matematicamente da alcune funzionalità di input. Ne abbiamo visto un esempio in Iperparametri e convalida del modello quando abbiamo costruito funzionalità polinomiali dai nostri dati di input. Abbiamo visto che potremmo convertire una regressione lineare in una regressione polinomiale non cambiando il modello, ma trasformando l'input!\n",
        "\n",
        "A esempio, questi dati chiaramente non possono essere ben descritti da una linea retta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vudvae9rEvc4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "81eb23ce-20f2-4ab3-b7dd-643296170dbb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([4, 2, 1, 3, 7])\n",
        "plt.scatter(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fyQhZHgdEvc4"
      },
      "source": [
        "Tuttavia, possiamo adattare una linea ai dati utilizzando la LinearRegression e ottenere il risultato ottimale:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "l3-IQ7CaEvc4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b0055b36-d6d8-452d-8a24-53e9501868ba"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "X = x[:, np.newaxis]\n",
        "model = LinearRegression().fit(X, y)\n",
        "yfit = model.predict(X)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, yfit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "otdBmXuFEvc4"
      },
      "source": [
        "È chiaro che abbiamo bisogno di un modello più sofisticato per descrivere la relazione tra X\n",
        "e y.\n",
        "\n",
        "Un approccio a questo problema consiste nel trasformare i dati, aggiungendo ulteriori colonne di funzionalità per garantire una maggiore flessibilità nel modello. A esempio, possiamo aggiungere caratteristiche polinomiali ai dati in questo modo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "F7e0lGmdEvc4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0fd786c3-ed4a-40e4-d464-2abd3ebb302e"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
        "X2 = poly.fit_transform(X)\n",
        "print(X2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wtMoNrQvEvc4"
      },
      "source": [
        "La matrice delle caratteristiche derivate ha una colonna che rappresenta X, una seconda colonna che rappresenta X2 e una terza colonna che rappresenta X3. Il calcolo di una regressione lineare su questo input espanso fornisce un adattamento molto più vicino ai nostri dati:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BXMV7hpYEvc4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b76ac866-fc86-432e-f4b5-b7c3ae7c3ff2"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression().fit(X2, y)\n",
        "yfit = model.predict(X2)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, yfit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7vwAv-EmEvc5"
      },
      "source": [
        "## Gestione Dati mancanti\n",
        "\n",
        "Un'altra esigenza comune nell'ingegneria delle funzionalità è la gestione dei dati mancanti. Abbiamo già discusso la gestione dei dati mancanti e abbiamo visto che spesso il valore NaN  viene utilizzato per contrassegnare i valori mancanti. A esempio, potremmo avere un set di dati simile a questo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-zfF8r_9Evc6",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from numpy import nan\n",
        "X = np.array([[ nan, 0,   3  ],\n",
        "              [ 3,   7,   9  ],\n",
        "              [ 3,   5,   2  ],\n",
        "              [ 4,   nan, 6  ],\n",
        "              [ 8,   8,   1  ]])\n",
        "y = np.array([14, 16, -1,  8, -5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "thJLvnY6Evc6"
      },
      "source": [
        "Quando applichiamo un tipico modello di machine learning a tali dati, dovremo prima sostituire i dati mancanti con un valore di riempimento appropriato. Questo è noto come gestione dei valori mancanti e le strategie vanno da semplici (ad esempio, sostituire i valori mancanti con la media della colonna) a sofisticate (ad esempio, utilizzando il completamento della matrice o un modello robusto per gestire tali dati).\n",
        "\n",
        "Gli approcci sofisticati tendono ad essere molto specifici per l'applicazione e non li approfondiremo. Per un approccio di imputazione di base, utilizzando la media, la mediana o il valore più frequente, Scikit-Learn fornisce la classe Imputer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "alxoxZfGEvc6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8435e4e3-7d62-4e9b-d77f-65755b78c9e6"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "X2 = imp.fit_transform(X)\n",
        "X2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wxv62ByCEvc6"
      },
      "source": [
        "Vediamo che nei dati risultanti i due valori mancanti sono stati sostituiti con la media dei valori rimanenti nella colonna. Questi dati imputati possono quindi essere inseriti direttamente, ad esempio, in uno stimatore LinearRegression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LRedAuOtEvc6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "28a1b4b2-41a8-41cf-f98e-5cd4d7c072ae"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression().fit(X2, y)\n",
        "model.predict(X2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MyaHp-SHEvc6"
      },
      "source": [
        "## Pipeline di funzionalità\n",
        "\n",
        "Con uno qualsiasi degli esempi precedenti, può diventare rapidamente noioso eseguire le trasformazioni manualmente, soprattutto se si desidera mettere insieme più passaggi. A esempio, potremmo volere una pipeline di elaborazione simile a questa:\n",
        "\n",
        "- Assegnazione valori mancanti utilizzando la media;\n",
        "- Trasformazione delle caratteristiche in quadratiche;\n",
        "- Adattamento di una regressione lineare.\n",
        "Per semplificare questo tipo di pipeline di elaborazione, Scikit-Learn fornisce un oggetto Pipeline che può essere utilizzato come segue:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bq86vpfWEvc-",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model = make_pipeline(SimpleImputer(strategy='mean'),\n",
        "                      PolynomialFeatures(degree=2),\n",
        "                      LinearRegression())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ftn5_fS6Evc-"
      },
      "source": [
        "Questa pipeline appare e si comporta come un oggetto Scikit-Learn standard e applicherà tutti i passaggi specificati a qualsiasi dato di input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ppio_SL6Evc-",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "97ebcd52-f6ca-42e2-b3b7-a736ed6301a6"
      },
      "outputs": [],
      "source": [
        "model.fit(X, y)  # X with missing values, from above\n",
        "print(y)\n",
        "print(model.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "D8Sm0jXtEvc-"
      },
      "source": [
        "Come potete vedere tutti i passaggi del modello vengono applicati automaticamente."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,md"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
